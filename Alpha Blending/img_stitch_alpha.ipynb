{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":671,"status":"ok","timestamp":1697726637287,"user":{"displayName":"Maleeha Sheikh","userId":"00126436052112094893"},"user_tz":240},"id":"cpyxooKMot7-"},"outputs":[],"source":["import sys\n","import cv2\n","import numpy as np\n","from scipy.sparse import diags\n","from scipy.sparse.linalg import spsolve\n","from scipy.sparse import csr_matrix\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1mAiXa7rD4leUYrSW3N0ZWsu57bEn0Dy8"},"executionInfo":{"elapsed":24778,"status":"ok","timestamp":1697726735620,"user":{"displayName":"Maleeha Sheikh","userId":"00126436052112094893"},"user_tz":240},"id":"ovXr4nAHox60","outputId":"575d38f3-a1ab-48d9-daf1-0c34f07d9e7f"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["# Load our images\n","image1 = cv2.imread(\"image1.jpg\")\n","image2 = cv2.imread(\"image2.jpg\")\n","image3 = cv2.imread(\"image3.jpg\")\n","image4 = cv2.imread(\"image4.jpg\")\n","\n","images = [image1, image2, image3, image4]\n","\n","result = images[0]\n","\n","# Convert images to grayscale\n","gray_images = [cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in images]\n","for i in range(len(gray_images)):\n","    cv2_imshow(gray_images[i])"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1FrHCpqliH7Tvrv7btbd7WVe801Qnua8i"},"executionInfo":{"elapsed":45743,"status":"ok","timestamp":1697727440985,"user":{"displayName":"Maleeha Sheikh","userId":"00126436052112094893"},"user_tz":240},"id":"sD0NFtPPpjSO","outputId":"eebca8fc-4423-4a7d-9a4f-c15120272e7d"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["#Using ORB detector\n","orb = cv2.ORB_create()\n","\n","# Find keypoints and descriptors for each image\n","keypoints1, descriptors1 = orb.detectAndCompute(image1, None)\n","keypoints2, descriptors2 = orb.detectAndCompute(image2, None)\n","keypoints3, descriptors3 = orb.detectAndCompute(image3, None)\n","keypoints4, descriptors4 = orb.detectAndCompute(image4, None)\n","\n","# Draw keypoints on images\n","image1_with_keypoints = cv2.drawKeypoints(image1, keypoints1, None, color=(0, 255, 0), flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n","image2_with_keypoints = cv2.drawKeypoints(image2, keypoints2, None, color=(0, 255, 0), flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n","image3_with_keypoints = cv2.drawKeypoints(image3, keypoints3, None, color=(0, 255, 0), flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n","image4_with_keypoints = cv2.drawKeypoints(image4, keypoints4, None, color=(0, 255, 0), flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n","\n","# Display images with keypoints\n","cv2_imshow(image1_with_keypoints)\n","cv2_imshow(image2_with_keypoints)\n","cv2_imshow(image3_with_keypoints)\n","cv2_imshow(image4_with_keypoints)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2425,"status":"ok","timestamp":1697727454961,"user":{"displayName":"Maleeha Sheikh","userId":"00126436052112094893"},"user_tz":240},"id":"3nGxMjOaSTxx"},"outputs":[],"source":["# Create a BFMatcher (BruteForce) object\n","bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n","\n","# Match descriptors using knn\n","matches12 = bf.match(descriptors1, descriptors2)\n","matches23 = bf.match(descriptors2, descriptors3)\n","matches34 = bf.match(descriptors3, descriptors4)\n","\n","# Sort the matches based on distance\n","matches12 = sorted(matches12, key=lambda x: x.distance)\n","matches23 = sorted(matches23, key=lambda x: x.distance)\n","matches34 = sorted(matches34, key=lambda x: x.distance)\n","\n","# Take top 50 matches\n","good_matches12 = matches12[:50]\n","good_matches23 = matches23[:50]\n","good_matches34 = matches34[:50]"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2365,"status":"ok","timestamp":1697727462656,"user":{"displayName":"Maleeha Sheikh","userId":"00126436052112094893"},"user_tz":240},"id":"XEeaXWX-Sc6n"},"outputs":[],"source":["# Extract matched keypoints\n","src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches12]).reshape(-1, 1, 2)\n","dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches12]).reshape(-1, 1, 2)\n","H12, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n","\n","src_pts = np.float32([keypoints2[m.queryIdx].pt for m in good_matches23]).reshape(-1, 1, 2)\n","dst_pts = np.float32([keypoints3[m.trainIdx].pt for m in good_matches23]).reshape(-1, 1, 2)\n","H23, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n","\n","src_pts = np.float32([keypoints3[m.queryIdx].pt for m in good_matches34]).reshape(-1, 1, 2)\n","dst_pts = np.float32([keypoints4[m.trainIdx].pt for m in good_matches34]).reshape(-1, 1, 2)\n","H34, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1HxVXr-GbJw60vU3swJoVqaxhmuHhccoR"},"id":"xpj6hOIwSg45","outputId":"f7713d16-6854-4a87-a8d5-4789763a4aac"},"outputs":[],"source":["# Warp images\n","panorama = cv2.warpPerspective(image1, H12, (image1.shape[1] + image2.shape[1], image1.shape[0]))\n","panorama[0:image2.shape[0], 0:image2.shape[1]] = image2\n","\n","temp = cv2.warpPerspective(image3, H23, (image3.shape[1] + image4.shape[1], image3.shape[0]))\n","temp[0:image4.shape[0], 0:image4.shape[1]] = image4\n","\n","final_panorama = cv2.warpPerspective(panorama, H34, (panorama.shape[1] + temp.shape[1], panorama.shape[0]))\n","final_panorama[0:temp.shape[0], 0:temp.shape[1]] = temp\n","\n","# Blend images using alpha blending\n","alpha = 0.5  # You can adjust the alpha value for different blending effects\n","\n","# Blend image1 and image2\n","blended_1_2 = cv2.addWeighted(image1, 1 - alpha, image2, alpha, 0)\n","\n","# Blend blended_1_2 and image3\n","blended_1_2_3 = cv2.addWeighted(blended_1_2, 1 - alpha, image3, alpha, 0)\n","\n","# Blend blended_1_2_3 and image4\n","final_panorama = cv2.addWeighted(blended_1_2_3, 1 - alpha, image4, alpha, 0)\n","\n","# Display the stitched image with alpha blending\n","cv2_imshow(final_panorama)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n"]}],"metadata":{"accelerator":"TPU","colab":{"machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}