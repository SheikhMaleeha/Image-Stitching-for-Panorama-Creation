import sys
import cv2
import numpy as np

from google.colab.patches import cv2_imshow


# Load our images
img1 = cv2.imread("image1.jpg")
img2 = cv2.imread("image2.jpg")
img3 = cv2.imread("image3.jpg")
img4 = cv2.imread("image4.jpg")

img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
img3_gray = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)
img4_gray = cv2.cvtColor(img4, cv2.COLOR_BGR2GRAY)

cv2_imshow(img1_gray)
cv2_imshow(img2_gray)
cv2_imshow(img3_gray)
cv2_imshow(img4_gray)


# Create our ORB detector and detect keypoints and descriptors
orb = cv2.ORB_create(nfeatures=2000)

# Find the key points and descriptors with ORB
keypoints1, descriptors1 = orb.detectAndCompute(img1_gray, None)
keypoints2, descriptors2 = orb.detectAndCompute(img2_gray, None)
keypoints3, descriptors3 = orb.detectAndCompute(img3_gray, None)
keypoints4, descriptors4 = orb.detectAndCompute(img4_gray, None)

cv2_imshow(cv2.drawKeypoints(img1, keypoints1, None, (255, 0, 255)))
cv2_imshow(cv2.drawKeypoints(img2, keypoints2, None, (255, 0, 255)))
cv2_imshow(cv2.drawKeypoints(img3, keypoints3, None, (255, 0, 255)))
cv2_imshow(cv2.drawKeypoints(img4, keypoints4, None, (255, 0, 255)))


# Create a BFMatcher (Brute Force Matcher)
bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)


# Match descriptors
matches12 = bf.match(descriptors1, descriptors2)
matches23 = bf.match(descriptors2, descriptors3)
matches34 = bf.match(descriptors3, descriptors4)

# Sort matches by distance
matches12 = sorted(matches12, key=lambda x: x.distance)
matches23 = sorted(matches23, key=lambda x: x.distance)
matches34 = sorted(matches34, key=lambda x: x.distance)


N = 50
matches12 = matches12[:N]
matches23 = matches23[:N]
matches34 = matches34[:N]

# Extract matching points
src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches12]).reshape(-1, 1, 2)
dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches12]).reshape(-1, 1, 2)
M12, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)

# Repeat for the other pairs
src_pts = np.float32([keypoints2[m.queryIdx].pt for m in matches23]).reshape(-1, 1, 2)
dst_pts = np.float32([keypoints3[m.trainIdx].pt for m in matches23]).reshape(-1, 1, 2)
M23, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)

src_pts = np.float32([keypoints3[m.queryIdx].pt for m in matches34]).reshape(-1, 1, 2)
dst_pts = np.float32([keypoints4[m.trainIdx].pt for m in matches34]).reshape(-1, 1, 2)
M34, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)


h1, w1 = img1_gray.shape
h2, w2 = img2_gray.shape
h3, w3 = img3_gray.shape
h4, w4 = img4_gray.shape

# Calculate dimensions of the stitched image
h_total = max(h1, h2, h3, h4)
w_total = w1 + w2 + w3 + w4


panorama = np.zeros((h_total, w_total, 3), dtype=np.uint8)
# Warp the images to the panoramic view
panorama[0:h1, 0:w1] = img1
panorama[0:h2, w1:w1+w2] = cv2.warpPerspective(img2, M12, (w_total, h_total))[0:h2, 0:w2]
panorama[0:h3, w1+w2:w1+w2+w3] = cv2.warpPerspective(img3, M12.dot(M23), (w_total, h_total))[0:h3, 0:w3]
panorama[0:h4, w1+w2+w3:w1+w2+w3+w4] = cv2.warpPerspective(img4, M12.dot(M23).dot(M34), (w_total, h_total))[0:h4, 0:w4]


# Display or save the resulting panoramic image
cv2.imwrite('panoramic_image.jpg', panorama)
cv2_imshow(panorama)
cv2.waitKey(0)
cv2.destroyAllWindows()
